<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLOv8n Image Object Detection Test</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f0f0f0;
            margin: 0;
            padding: 20px;
        }
        h1 {
            color: #333;
        }
        #controls {
            margin-bottom: 20px;
        }
        #fileInput {
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
            cursor: pointer;
        }
        #canvasContainer {
            position: relative;
            width: fit-content;
            margin: 20px auto;
            border: 2px solid #ccc;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            background-color: #fff;
        }
        #canvas {
            display: block;
            max-width: 100%;
            height: auto;
        }
        #status {
            margin-top: 10px;
            font-size: 1.1em;
            color: #555;
        }
        .error-message {
            color: red;
            font-weight: bold;
        }
        .success-message {
            color: green;
        }
        /* Hidden image element, used for loading but not displayed */
        #hiddenImage {
            display: none;
        }
    </style>
</head>
<body>
    <h1>YOLOv8n Image Object Detection Test</h1>

    <div id="controls">
        <input type="file" id="fileInput" accept="image/*">
    </div>

    <div id="status">Loading model...</div>

    <div id="canvasContainer">
        <canvas id="canvas"></canvas>
    </div>

    <img id="hiddenImage" style="display: none;">

    <script>
        const fileInput = document.getElementById('fileInput');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusDiv = document.getElementById('status');
        const hiddenImage = document.getElementById('hiddenImage'); // Used to load image data

        let model;

        // IMPORTANT: Ensure this order matches your model's training classes
        const classLabels = [
            'AppleFritter', 'Blueberry-donut', 'Blueberry-muffin', 'Blueberry-munchkin',
            'BostonStar-donut', 'Capital-donut', 'Chocolate-munchkin', 'ChocolateFrost-donut',
            'ChocolateFrostSprinkle-donut', 'CinnamonRaisin-bagel', 'CoffeeCake-muffin', 'CoffeeRoll',
            'Corn-muffin', 'Donuts', 'DoubleChoc-donut', 'Everything-bagel',
            'Frechcrueller-donut', 'Glaze-donut', 'Glaze-munchkin', 'GlazedChoc-donut',
            'JellyStar-donut', 'Kremestar-donut', 'MapleFrost-donut', 'Multigrain-Bagel',
            'OldFashion-donut', 'PieApple', 'Plain-bagel', 'Sesame-bagel',
            'Sourcream', 'Starspangle-donut', 'Strawberry-donut', 'Vanilladonut'
        ];

        // Model parameters (adjust if your YOLOv8n has different output/input sizes)
        const INPUT_SIZE = 640; // Default YOLOv8 input size
        const NUM_CLASSES = classLabels.length;
        const IOU_THRESHOLD = 0.45; // Intersection over Union threshold for NMS
        const SCORE_THRESHOLD = 0.01; // Confidence score threshold for detection filtering
        const MAX_DETECTIONS = 100; // Maximum number of detections after NMS

        // Function to load the model
        async function loadYOLOModel() {
            statusDiv.textContent = 'Loading model... This might take a moment.';
            try {
                model = await tf.loadGraphModel('src/models/my_yolo_model/model.json');
                statusDiv.textContent = 'Model loaded successfully! Upload an image to start detection.';
                statusDiv.classList.add('success-message');

                console.log('Model loaded!');
                console.log('Model input shape:', model.inputs[0].shape);
                console.log('Model output shape(s):', model.outputs.map(o => o.shape));

                // Warm up the model with dummy input
                const dummyInput = tf.zeros(model.inputs[0].shape);
                await model.executeAsync(dummyInput);
                dummyInput.dispose();
                console.log('Model warmed up.');

            } catch (error) {
                console.error('Failed to load model:', error);
                statusDiv.textContent = `Error loading model: ${error.message}. Check console for details.`;
                statusDiv.classList.add('error-message');
            }
        }

        // Function to preprocess the image for the model
        function preprocess(source) {
            return tf.tidy(() => {
                const img = tf.browser.fromPixels(source).toFloat();
                const resized = tf.image.resizeBilinear(img, [INPUT_SIZE, INPUT_SIZE]);
                const normalized = resized.div(255.0);
                const expanded = normalized.expandDims(0);
                return expanded;
            });
        }

        // Function to post-process the model output for YOLOv8
        async function postprocessOutput(predictions) {
            if (!predictions || predictions.length === 0) {
                console.warn("No predictions received from model.");
                return { boxes: [], scores: [], classIds: [] };
            }

            const outputTensor = Array.isArray(predictions) ? predictions[0] : predictions;

            if (!outputTensor || outputTensor.shape.length !== 3) {
                console.error("Unexpected output tensor shape from model:", outputTensor ? outputTensor.shape : 'undefined');
                statusDiv.textContent = `Error: Unexpected model output shape. Expected 3 dimensions.`;
                statusDiv.classList.add('error-message');
                return { boxes: [], scores: [], classIds: [] };
            }

            console.log("Raw output tensor shape:", outputTensor.shape);

            const transposedOutput = tf.transpose(outputTensor, [0, 2, 1]).squeeze([0]);

            console.log("Transposed and squeezed output shape:", transposedOutput.shape);

            const [num_boxes, num_attributes] = transposedOutput.shape;
            const num_coords = 4; // x, y, width, height

            // --- IMPORTANT: Adjust this condition based on your actual model's attributes ---
            // If your model has 4 coords + 1 objectness + NUM_CLASSES, it should be 4 + 1 + NUM_CLASSES
            // If your model has 4 coords + NUM_CLASSES (objectness combined or not explicit), it should be 4 + NUM_CLASSES
            // Check your console for 'Transposed and squeezed output shape: [8400, XXX]' to find XXX
            // if (num_attributes !== (num_coords + 1 + NUM_CLASSES)) { // Assuming 4 coords + 1 objectness + NUM_CLASSES
            //     console.error(`Mismatch in attributes: Expected ${num_coords + NUM_CLASSES}, got ${num_attributes}`);
            //     statusDiv.textContent = `Error: Model attributes mismatch. Expected ${num_coords + 1 + NUM_CLASSES}, got ${num_attributes}. Please check NUM_CLASSES or post-processing logic.`;
            //     statusDiv.classList.add('error-message');
            //     transposedOutput.dispose();
            //     return { boxes: [], scores: [], classIds: [] };
            // }

            const decoded_detections = tf.tidy(() => {
                const rawBoxes = transposedOutput.slice([0, 0], [num_boxes, num_coords]);
                const objectnessScores = transposedOutput.slice([0, num_coords], [num_boxes, 1]).squeeze();
                const classScores = transposedOutput.slice([0, num_coords], [num_boxes, NUM_CLASSES]);

                const sigmoidObjectness = tf.sigmoid(objectnessScores);
                const sigmoidClassScores = tf.sigmoid(classScores);

                const scores = sigmoidObjectness.expandDims(1).mul(sigmoidClassScores);

                const x_center = rawBoxes.slice([0, 0], [num_boxes, 1]);
                const y_center = rawBoxes.slice([0, 1], [num_boxes, 1]);
                const width = rawBoxes.slice([0, 2], [num_boxes, 1]);
                const height = rawBoxes.slice([0, 3], [num_boxes, 1]);

                // Convert to x1, y1, x2, y2 format relative to INPUT_SIZE
                const x1 = x_center.sub(width.div(2));
                const y1 = y_center.sub(height.div(2));
                const x2 = x_center.add(width.div(2));
                const y2 = y_center.add(height.div(2));

                const boxes = tf.concat([y1, x1, y2, x2], 1); // Format for NMS: [y1, x1, y2, x2]

                return { boxes, scores };
            });

            const { values: maxScores, indices: classIds } = tf.topk(decoded_detections.scores, 1, true);
            const reshapedMaxScores = maxScores.squeeze();

            console.log("Boxes shape for NMS:", decoded_detections.boxes.shape);
            console.log("Scores shape for NMS:", reshapedMaxScores.shape);

            const selectedIndices = await tf.image.nonMaxSuppressionAsync(
                decoded_detections.boxes,
                reshapedMaxScores,
                MAX_DETECTIONS,
                IOU_THRESHOLD,
                SCORE_THRESHOLD
            );

            const selectedBoxes = tf.gather(decoded_detections.boxes, selectedIndices);
            const selectedScores = tf.gather(reshapedMaxScores, selectedIndices);
            const selectedClassIds = tf.gather(classIds.squeeze(), selectedIndices);

            decoded_detections.boxes.dispose();
            decoded_detections.scores.dispose();
            transposedOutput.dispose();
            maxScores.dispose();
            classIds.dispose();
            selectedIndices.dispose();
            outputTensor.dispose();

            return {
                boxes: selectedBoxes.arraySync(),
                scores: selectedScores.arraySync(),
                classIds: selectedClassIds.arraySync()
            };
        }

        // Function to draw bounding boxes on the canvas
        function drawBoxes(detections, originalImage) {
            // Set canvas size to match the original image
            canvas.width = originalImage.naturalWidth;
            canvas.height = originalImage.naturalHeight;

            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(originalImage, 0, 0, canvas.width, canvas.height);

            const scaleX = canvas.width / INPUT_SIZE;
            const scaleY = canvas.height / INPUT_SIZE;

            detections.boxes.forEach((box, i) => {
                const y1 = box[0] * scaleY;
                const x1 = box[1] * scaleX;
                const y2 = box[2] * scaleY;
                const x2 = box[3] * scaleX;

                const score = detections.scores[i];
                const classId = detections.classIds[i];
                const label = classLabels[classId] || `Unknown Class (${classId})`;

                ctx.strokeStyle = '#00FFFF'; // Cyan
                ctx.lineWidth = 2;
                ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

                ctx.fillStyle = '#00FFFF';
                const text = `${label}: ${Math.round(score * 100)}%`;
                ctx.font = '18px Arial';
                const textX = x1;
                const textY = y1 > 20 ? y1 - 8 : y1 + 25;

                ctx.fillText(text, textX, textY);
            });
            statusDiv.textContent = `Detected ${detections.boxes.length} objects.`;
        }

        // Main image detection function
        async function detectImage(imgElement) {
            if (!model) {
                statusDiv.textContent = 'Model not loaded. Please wait.';
                return;
            }

            statusDiv.textContent = 'Processing image...';
            tf.engine().startScope();
            try {
                const inputTensor = preprocess(imgElement);
                const predictions = await model.executeAsync(inputTensor); // You can change to .execute() once stable

                const detections = await postprocessOutput(predictions);
                drawBoxes(detections, imgElement);

                inputTensor.dispose();
                if (Array.isArray(predictions)) {
                    predictions.forEach(p => p.dispose());
                } else {
                    predictions.dispose();
                }
            } catch (error) {
                console.error('Error during detection:', error);
                statusDiv.textContent = `Error during detection: ${error.message}. Check console.`;
                statusDiv.classList.add('error-message');
            } finally {
                tf.engine().endScope();
            }
        }

        // Event listener for file input
        fileInput.addEventListener('change', (event) => {
            const file = event.target.files[0];
            if (!file) {
                return;
            }

            const reader = new FileReader();
            reader.onload = (e) => {
                hiddenImage.onload = () => {
                    detectImage(hiddenImage);
                };
                hiddenImage.src = e.target.result;
            };
            reader.readAsDataURL(file);
        });

        // Initialize model loading on page load
        async function init() {
            await loadYOLOModel();
        }

        init();
    </script>
</body>
</html>